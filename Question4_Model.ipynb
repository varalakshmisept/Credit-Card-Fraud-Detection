{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from imblearn.over_sampling import SMOTE \n",
    "import collections\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)\n",
    "# dropping unnecessary columns\n",
    "new_df=df.drop(columns=['accountNumber','customerId','transactionDateTime','currentExpDate','accountOpenDate','dateOfLastAddressChange','previousTransaction','merchantName','cardCVV','enteredCVV','cardLast4Digits','transactionDate','transactionWeek','transactionMonth','transactionQuarter'])\n",
    "# converting the boolean features(True/False) into 1/0\n",
    "new_df[['differentCountry','expirationDateKeyInMatch', 'isFraud','cardPresent','reversalTransaction','multiSwipeTransaction','incorrectCVV']] =new_df[['differentCountry','expirationDateKeyInMatch', 'isFraud','cardPresent','reversalTransaction','multiSwipeTransaction','incorrectCVV']].astype(int)\n",
    "new_df = pd.get_dummies(data=new_df, columns=['transactionType','acqCountry', 'merchantCountryCode','posEntryMode','posConditionCode','merchantCategoryCode'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_df['isFraud']\n",
    "X = new_df.drop(columns = ['isFraud'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(X_train, X_test, Y_train, Y_test):\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, y_pred)\n",
    "    print('AUC' + str(auc(fpr, tpr)))\n",
    "    pre = precision_score(Y_test,y_pred)\n",
    "    rec = recall_score(Y_test, y_pred)\n",
    "    print('Precision: '+str(pre))\n",
    "    print('Recall: '+str(rec))\n",
    "    return lr, pre, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTree(X_train, X_test, Y_train, Y_test):\n",
    "    dt = DecisionTreeClassifier()\n",
    "    print('Decision Tree Classifier:')\n",
    "    dt.fit(X_train, Y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, y_pred)\n",
    "    print('AUC' + str(auc(fpr, tpr)))\n",
    "    pre = precision_score(Y_test,y_pred)\n",
    "    rec = recall_score(Y_test, y_pred)\n",
    "    print('Precision: '+str(pre))\n",
    "    print('Recall: '+str(rec))\n",
    "    return dt,pre,rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestClassifier(X_train, X_test, Y_train, Y_test):\n",
    "    print('Random Forest Classifier')\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, Y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test, y_pred)\n",
    "    print('AUC' + str(auc(fpr, tpr)))\n",
    "    pre = precision_score(Y_test,y_pred)\n",
    "    rec = recall_score(Y_test, y_pred)\n",
    "    print('Precision: '+str(pre))\n",
    "    print('Recall: '+str(rec))\n",
    "    return rf, pre, rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientBoostingClassifier(X_train, X_test, Y_train, Y_test):\n",
    "    gr = GradientBoostingClassifier()\n",
    "    print('GradientBoostingClassifier')\n",
    "    gr.fit(X_train, Y_train)\n",
    "    y_pred = gr.predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    print('AUC' + str(auc(fpr, tpr)))\n",
    "    pre = precision_score(Y_test,y_pred)\n",
    "    rec = recall_score(Y_test, y_pred)\n",
    "    print('Precision: '+str(pre))\n",
    "    print('Recall: '+str(rec))\n",
    "    return gr, pre, rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmsklearn(X_train, X_test, Y_train, Y_test):\n",
    "    svc = svm.SVC()\n",
    "    print('SVM')\n",
    "    svc.fit(X_train, Y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    print('AUC' + str(auc(fpr, tpr)))\n",
    "    pre = precision_score(Y_test,y_pred)\n",
    "    rec = recall_score(Y_test, y_pred)\n",
    "    print('Precision: '+str(pre))\n",
    "    print('Recall: '+str(rec))\n",
    "    return gr, pre, rec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1 - Traning on Train data and testing on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "rf,pre,recall = randomForestClassifier(X_train, X_test, y_train, y_test)\n",
    "#rf,pre,recall = svmsklearn(X_train, X_test, y_train, y_test)\n",
    "dt,pre,recall = decisionTree(X_train, X_test, y_train, y_test)\n",
    "gr,pre,recall = gradientBoostingClassifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importantFeatures(rf,X_train):\n",
    "    names = list(X_train.columns)\n",
    "    importances = rf.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    new_indices = indices[:10]\n",
    "    features = X_train.columns[indices]\n",
    "    indices = rf.feature_importances_[indices]\n",
    "    features = list(features[:20])\n",
    "    indices = list(indices[:20])\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.bar(features, indices)\n",
    "    plt.show()\n",
    "    return features, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, indices = importantFeatures(rf,X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 - undersampling the majority class data in train set and validating on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating over various ratios \n",
    "pre = []\n",
    "rec = []\n",
    "for i in range(1,7):\n",
    "    newX = X_train\n",
    "    newX['isFraud'] = y_train\n",
    "    X_train_notFraud =  newX[newX['isFraud']==0] \n",
    "    X_train_notFraud = X_train_notFraud.sample(frac = i*0.01, random_state = 42)\n",
    "    X_train_Fraud = newX[newX['isFraud']==1]\n",
    "    dfunder = X_train_notFraud.append(X_train_Fraud) \n",
    "    y_under = dfunder['isFraud']\n",
    "    X_under = dfunder.drop(columns = ['isFraud'])\n",
    "\n",
    "\n",
    "    lr_under, pre1,rec1 = logisticRegression(X_under, X_test, y_under,y_test)\n",
    "    pre.append(pre1)\n",
    "    rec.append(rec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 - Smote analysis on the train dataset to oversample the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling the majority class data\n",
    "y = new_df['isFraud']\n",
    "X = new_df.drop(columns = ['isFraud'])\n",
    "newX = X\n",
    "newX['isFraud'] = y\n",
    "X_train_notFraud =  newX[newX['isFraud']==0] \n",
    "X_train_notFraud = X_train_notFraud.sample(frac = 0.9, random_state = 42)\n",
    "X_train_Fraud = newX[newX['isFraud']==1]\n",
    "dfsmote = X_train_notFraud.append(X_train_Fraud) \n",
    "\n",
    "# Oversampling the minority class data (SMOTE)\n",
    "y = dfsmote['isFraud']\n",
    "X = dfsmote.drop(columns = ['isFraud'])\n",
    "\n",
    "sm = SMOTE(sampling_strategy = 0.6,random_state=42)\n",
    "X_sm, y_sm = sm.fit_resample(X, y)\n",
    "print(f'''Shape of X before SMOTE: {X.shape} Shape of X after SMOTE: {X_sm.shape}''')\n",
    "print('\\n positive and negative classes:')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=42, stratify = y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnew, val1, val2 = logisticRegression(X_train, X_test, y_train,y_test)\n",
    "rfnew, val1, val2 = randomForestClassifier(X_train, X_test, y_train,y_test)\n",
    "dtnew, val1, val2 = decisionTree(X_train, X_test, y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
